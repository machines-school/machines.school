---
title: 'นี่คือทั้งหมดที่คุณต้องรู้: จุดเปลี่ยนสำคัญของโมเดล LLM (Large Language Model)'
description: 'This Is All You Need: Key Shifts in the Evolution of Large Language Models'
featuredImage: 
    url: '/featured-images/evolution-of-large-language-models.webp'
    alt: 'จุดเปลี่ยนสำคัญของโมเดล LLM (Large Language Model)'
author: 'Athiwat Hirunworawongkun'
xAccount: '@athivvat'
date: '2025-07-14'
tags: ['AI', 'NLP', 'LLM']
category: 'AI'
isPublished: true
isFeatured: true
isDraft: false
---

ทุกวันนี้ เทคโนโลยี AI พัฒนาอย่างรวดเร็วเสียจนแทบตามไม่ทัน การพยายามทำความเข้าใจทุกการเปลี่ยนแปลงที่เกิดขึ้นแบบรายวันจึงไม่ใช่เรื่องง่าย เพราะต้องใช้ทั้งพลังงาน เวลา และความเข้าใจในเชิงลึก

แต่แทนที่จะพยายาม “ตามทุกกระแสให้ทัน” บางครั้งการ ถอยออกมาเพื่อมองแรงผลักดันเบื้องหลัง — หรือที่เรียกว่า **“แรงจูงใจในการเปลี่ยนแปลง” (motivation)** กลับช่วยให้เราเห็นภาพรวมของวงการได้ชัดเจนกว่าเดิม เพราะเบื้องหลังการเปลี่ยนแปลงหลายครั้ง มักเกิดจาก “จุดเปลี่ยน” เพียงไม่กี่จุดเท่านั้น

เราทุกคนคงคุ้นเคยกับความสามารถของโมเดลภาษาใหญ่ (Large Language Models หรือ LLMs) กันเป็นอย่างดี ไม่ว่าจะเป็นการสรุปเอกสาร ตอบคำถาม วิเคราะห์ข้อมูล หรือแม้แต่เขียนโค้ดให้แบบอัตโนมัติ

แต่คำถามสำคัญคือ

> "โมเดลเหล่านี้ทำงานอย่างไร?"<br/>
> "แล้วกว่าจะมาถึงจุดนี้ได้ มันผ่านอะไรมาบ้าง?"<br/>
> "ทำไมมันถึงฉลาดขนาดนี้?"

ในบทความนี้ คุณจะได้รู้จักกับ 4 จุดเปลี่ยนสำคัญ (Key Shifts) ที่เปลี่ยนโฉมหน้าวงการประมวลผลภาษาธรรมชาติ (Natural Language Processing หรือ NLP) ไปตลอดกาล

1. **ยุคสถิติ (Pre-2013)**: จากการนับคำธรรมดา ๆ ด้วยสถิติ
2. **ยุค Word2Vec (2013-2017)**: การปฏิวัติจาก "การนับ" สู่ "การเข้าใจความหมาย"
3. **ยุค RNN/LSTM (2014-2017)**: เมื่อลำดับของคำเริ่มมีความหมาย แต่ความจำยังสั้น
4. **ยุค Transformer (2017-ปัจจุบัน)**: "Attention Is All You Need" ที่เปลี่ยนทุกอย่าง

การเข้าใจจุดเปลี่ยนเหล่านี้ไม่เพียงแค่ช่วยให้คุณเข้าใจหลักการทำงานของ LLM ที่ใช้งานอยู่ในปัจจุบันได้ดีขึ้น แต่ยังเป็นพื้นฐานสำคัญที่จะช่วยให้คุณสามารถมองเห็นทิศทางการพัฒนาของเทคโนโลยี AI ในอนาคตได้อย่างมีหลักการและมีเหตุผล

# สิ่งที่คุณจะได้เรียนรู้

บทความนี้มีจุดประสงค์เพื่อเป็น **แนวทางหรือพื้นฐานความเข้าใจ (foundational guide)** สำหรับผู้ที่ต้องการศึกษาเรื่อง LLM อย่างจริงจัง โดยจะไม่ลงรายละเอียดทางเทคนิคที่ซับซ้อน แต่เน้นที่การทำความเข้าใจ แรงจูงใจและเหตุผลเบื้องหลัง ของแต่ละการเปลี่ยนแปลง

หลังจากอ่านบทความนี้แล้ว คุณจะมี **"แผนที่ความเข้าใจ" (mental map)** ที่จะช่วยให้การเรียนรู้เรื่อง LLM ในระดับลึกต่อไปเป็นไปได้อย่างมีทิศทางและมีประสิทธิภาพมากขึ้น

# การพัฒนาแบบลำดับขั้น: 4 จุดเปลี่ยนสำคัญ

## 1. ยุคก่อน 2013: การนับคำด้วยสถิติ

> "คอมพิวเตอร์ไม่เข้าใจความหมาย เพียงแค่นับความถี่"

**ปัญหาที่ต้องแก้** 

ลองจินตนาการว่าเราต้องการสอนคอมพิวเตอร์ให้ "เข้าใจภาษา" เหมือนที่มนุษย์เข้าใจ สมมติว่าเราพิมพ์ประโยคไม่สมบูรณ์ให้กับมันว่า:

> "แมวกำลังนอนอยู่บน..."

เราทุกคนสามารถเดาได้ทันทีว่า คำถัดไปน่าจะเป็น "โซฟา", "พรม", "เตียง", หรือ "เสื่อ" เพราะเราเข้าใจความหมายของคำว่า "แมว" (สัตว์เลี้ยงที่มักหาที่นอน) และคำว่า "นอน" (การกระทำที่ต้องมีพื้นผิว)

แต่ในยุคก่อน 2013 คอมพิวเตอร์ไม่ "เข้าใจ" คำเหล่านี้เลย มันเพียงแค่เป็นเครื่องจักรที่ นับความถี่ ว่าในข้อมูลที่เคยเห็นมา หลังจากคำว่า "บน" มักจะตามด้วยคำอะไรบ้าง

**วิธีการของยุคสถิติ**

ในยุคนี้ เทคโนโลยีหลักคือ Statistical Language Models (SLMs) ที่ใช้หลักการง่าย ๆ:

หลังจากคำว่า "แมวนอนบน" 

- "โซฟา" ปรากฏ 100 ครั้ง (ความน่าจะเป็น 40%)
- "เตียง" ปรากฏ 75 ครั้ง (ความน่าจะเป็น 30%)  
- "พรม" ปรากฏ 50 ครั้ง (ความน่าจะเป็น 20%)
- "โต๊ะ" ปรากฏ 25 ครั้ง (ความน่าจะเป็น 10%)

→ ระบบจะเลือก "โซฟา" เพราะมีความน่าจะเป็นสูงสุด

เทคนิคที่ใช้:

- **N-gram Models**: พิจารณา n คำล่าสุดเพื่อทำนายคำถัดไป
- **Hidden Markov Models**: ใช้สถานะทางไวยากรณ์ช่วยในการทำนาย
- **Maximum Entropy Models**: ใช้ features ต่าง ๆ ของคำในการคำนวณ

**ข้อดีและข้อเสีย**

ข้อดี:

- เรียบง่าย รวดเร็ว ใช้ทรัพยากรน้อย
- เข้าใจง่าย สามารถอธิบายผลลัพธ์ได้
- ทำงานได้ดีกับงานเฉพาะด้าน

ข้อเสีย:

- ไม่เข้าใจความหมาย: "แมว" และ "สุนัข" ถูกมองเป็นสัญลักษณ์ที่แตกต่างกันโดยสิ้นเชิง
- ความจำสั้น: จำได้แค่ไม่กี่คำย้อนหลัง
- Data Sparsity: หากคำไม่เคยปรากฏในข้อมูลฝึก จะจัดการไม่ได้

## 2. ปี 2013: Word2Vec - การปฏิวัติความหมาย

> "จากการนับคำ สู่การเรียนรู้ความหมายผ่านเวกเตอร์"

**จุดเปลี่ยนที่เปลี่ยนทุกอย่าง**

ในปี 2013 ทีมนักวิจัยจาก Google นำโดย Tomas Mikolov ได้เผยแพร่งานวิจัยที่เปลี่ยนแปลงวงการ NLP ไปตลอดกาล ชื่อว่า "Efficient Estimation of Word Representations in Vector Space" ซึ่งแนะนำเทคนิคใหม่ที่เรียกว่า Word2Vec

การเปลี่ยนแปลงครั้งนี้เป็นการ เปลี่ยนแนวคิดพื้นฐาน อย่างสิ้นเชิง:

```
ระบบเก่า: "แมว" = สัญลักษณ์ที่ 1, "สุนัข" = สัญลักษณ์ที่ 2
         ระยะห่าง("แมว", "สุนัข") = ระยะห่าง("แมว", "รถยนต์")
```

```
Word2Vec: "แมว" = [0.2, -0.4, 0.7, -0.1, ...]
          "สุนัข" = [0.3, -0.3, 0.8, -0.2, ...]  
          "รถยนต์" = [-0.5, 0.8, -0.2, 0.6, ...]
         
          → "แมว" กับ "สุนัข" อยู่ใกล้กันในพื้นที่ความหมาย
```

**หลักการ: เรียนรู้จากบริบท**

Word2Vec อิงตาม **Distributional Hypothesis**:

> "คำที่มีความหมายใกล้เคียงกัน มักจะปรากฏในบริบทที่คล้ายกัน"

ตัวอย่างการเรียนรู้:

- "แมวกำลังนอนอยู่บนโซฟา"
- "สุนัขกำลังนอนอยู่บนพรม"  
- "กระรอกกำลังวิ่งอยู่บนต้นไม้"

Word2Vec จะเรียนรู้ว่า "แมว", "สุนัข", "กระรอก" มีความหมายใกล้เคียงกัน เพราะมักปรากฏในบริบทที่คล้ายกัน (ทำกิจกรรมคล้าย ๆ กัน)

**สองแนวทางหลัก**

1. CBOW (Continuous Bag of Words)

- หลักการ: ทำนายคำกลางจากบริบทรอบข้าง
- ตัวอย่าง: ["แมว", "กำลัง", "___", "อยู่", "บน"] → ทำนาย "นอน"
- ข้อดี: เรียนรู้เร็ว เหมาะกับข้อมูลใหญ่

**2. Skip-Gram**
- **หลักการ**: ทำนายบริบทจากคำกลาง  
- **ตัวอย่าง**: `"นอน"` → ทำนาย `["แมว", "กำลัง", "อยู่", "บน"]`
- **ข้อดี**: เก่งกับคำหายาก ให้ผลลัพธ์ดีกว่าสำหรับ dataset เล็ก

#### ปาฏิหาริย์หารทางคณิตศาสตร์

สิ่งที่ทำให้ Word2Vec สร้างความตื่นตาตื่นใจคือความสามารถในการทำ **"เลขคณิต (Arithmetic)"**:

**ตัวอย่างที่โด่งดัง**:
```
king - man + woman = queen
กษัตริย์ - ผู้ชาย + ผู้หญิง = ราชินี

Paris - France + Italy = Rome
ปารีส - ฝรั่งเศส + อิตาลี = โรม

walking - walk + swim = swimming  
กำลังเดิน - เดิน + ว่าย = กำลังว่าย
```

**ทำไมถึงทำได้?** เพราะ Word2Vec เรียนรู้ที่จะแยกแยะ **มิติของความหมาย**:
- **มิติเพศ**: ทิศทางจาก man → woman
- **มิติสถานะ**: ทิศทางจาก commoner → royalty  
- **มิติไวยากรณ์**: ทิศทางจาก verb → gerund

#### ผลกระทบที่เปลี่ยนทุกอย่าง

1. **เริ่มต้น Representation Learning**: การเรียนรู้การแทนค่าข้อมูลอย่างอัตโนมัติ
2. **Transfer Learning ใน NLP**: เวกเตอร์จาก Word2Vec นำไปใช้กับงานอื่น ๆ ได้
3. **พื้นฐานของ Deep Learning**: เปิดทางสู่ neural networks ใน NLP

#### ข้อจำกัดที่เหลืออยู่

แม้ Word2Vec จะปฏิวัติวงการ แต่ก็ยังมีข้อจำกัด:

- **Static Embeddings**: แต่ละคำมีเวกเตอร์เดียว ไม่ว่าใช้ในบริบทไหน
  ```
  "I went to the bank to withdraw money" (ธนาคาร)
  "I sat by the river bank" (ฝั่งแม่น้ำ)
  → Word2Vec ให้เวกเตอร์เดียวกันทั้งสองความหมาย
  ```

- **ไม่เข้าใจลำดับ**: มอง "แมวไล่หนู" กับ "หนูไล่แมว" เหมือนกัน

---

## 3. ปี 2014-2017: RNN/LSTM - เข้าใจลำดับ แต่ความจำยังจำกัด

> **"เมื่อเครื่องจักรเริ่มเข้าใจลำดับ แต่ยังจำไม่ยาวพอ"**

#### ปัญหาใหม่ที่ต้องแก้

หลังจากที่ Word2Vec ช่วยให้คอมพิวเตอร์ "เข้าใจความหมายของคำ" แต่ละคำได้ดีขึ้นแล้ว นักวิจัยก็เริ่มตั้งคำถามใหม่:

> **"การเข้าใจคำแต่ละคำแยกกันเพียงพอแล้วหรือ?"**

เพราะในความเป็นจริง ภาษาไม่ได้มีแค่คำเดียว ๆ แต่เป็น **ลำดับของคำที่เรียงต่อกันอย่างมีความหมาย** และ **ลำดับนั้นสำคัญมาก**

**ตัวอย่างความสำคัญของลำดับ**:
```
"แมวไล่หนู" ≠ "หนูไล่แมว"  (คำเหมือนกัน แต่ความหมายตรงข้าม)
"ฉันไม่เคยบอกว่าเธอขโมยเงิน" (เน้นคำต่างกัน ความหมายต่างกัน)
"สีแดงรถยนต์" vs "รถยนต์สีแดง" (ไวยากรณ์ถูกต้องแตกต่างกัน)
```

#### เข้าสู่ยุค Sequential Learning

นี่คือจุดเริ่มต้นของ **Recurrent Neural Networks (RNN)** - Neural Network แบบ "วนซ้ำ" ที่ออกแบบมาเพื่อจัดการกับข้อมูลแบบลำดับโดยเฉพาะ

**หลักการทำงานของ RNN**:
```
Input:  "แมว"  →  "กำลัง"  →  "ไล่"  →  "หนู"
RNN:     h₁    →     h₂     →   h₃   →   h₄
         ↓      →     ↓      →    ↓    →   ↓
Output:  ?     →     ?      →    ?    →  "วิ่ง"
```

แต่ละขั้นตอน RNN จะ:
1. **รับ input**: คำปัจจุบัน + hidden state จากขั้นตอนก่อน
2. **ประมวลผล**: รวมข้อมูลใหม่กับความจำเก่า
3. **ส่งออก**: hidden state ใหม่สำหรับขั้นตอนถัดไป

#### ปัญหาใหญ่: Vanishing Gradient Problem

แต่ RNN มีข้อจำกัดร้ายแรงที่เรียกว่า **"Vanishing Gradient Problem"**:

เมื่อเรียนรู้จากข้อผิดพลาด สัญญาณแก้ไข (gradient) จะลดลงอย่างรวดเร็วเมื่อส่งย้อนกลับไป ทำให้:
- **ความจำสั้นมาก**: จำได้แค่ 5-10 คำย้อนหลัง
- **ไม่เข้าใจบริบทยาว**: ไม่สามารถเชื่อมโยงข้อมูลที่อยู่ไกลกัน

**ตัวอย่างปัญหา**:
```
"แมวที่เจ้าของเลี้ยงมาตั้งแต่เด็ก ซึ่งชอบกินปลาทูน่า และมักจะนอนอยู่บนโซฟาตัวโปรด 
กำลังไล่หนูที่วิ่งผ่านมา"

RNN จะ "ลืม" ว่าประโยคเริ่มต้นด้วย "แมว" 
และอาจสับสนว่าใครเป็นคนไล่ใคร
```

#### LSTM: การแก้ปัญหาความจำสั้น

**Long Short-Term Memory (LSTM)** เป็นนวัตกรรมที่แก้ปัญหา vanishing gradient ด้วยระบบ **"ประตูควบคุมข้อมูล"**

**สามประตูหลักของ LSTM**:

**1. Forget Gate: "ลืมอะไรบ้าง?"**
```
"John เป็นคนดี. Mary เป็นคนดี." 
→ เมื่อเจอ "Mary" ประตูลืมจะลดความสำคัญของ "John" ลง
```

**2. Input Gate: "จำอะไรใหม่บ้าง?"**
```
"Mary เป็นคนดี"
→ ประตูนำเข้าตัดสินใจว่าควรจำข้อมูลใหม่นี้หรือไม่
```

**3. Output Gate: "แสดงอะไรออกมาบ้าง?"**
```
ควบคุมว่าจะเอาข้อมูลไหนจากความจำมาใช้ในการตอบ
```

**การทำงานเปรียบเทียบ**:
```
RNN:  [ข้อมูลเก่า + ข้อมูลใหม่] → [ผลลัพธ์]
      ↓ ทุกอย่างผสมกัน ไม่มีการควบคุม

LSTM: ข้อมูลเก่า → [Forget Gate] → ข้อมูลที่เหลือ
      ข้อมูลใหม่ → [Input Gate]  → ข้อมูลที่เลือก
      ทั้งหมด    → [Output Gate] → ผลลัพธ์
```

#### GRU: LSTM เวอร์ชันเรียบง่าย

**Gated Recurrent Unit (GRU)** เป็น "LSTM แบบง่าย" โดยรวม gates เป็น 2 ตัว:

```
LSTM: Forget Gate + Input Gate + Output Gate = 3 ประตู
GRU:  Update Gate + Reset Gate = 2 ประตู

→ GRU: เร็วกว่า พารามิเตอร์น้อยกว่า แต่ยืดหยุ่นน้อยกว่า
```

#### Sequence-to-Sequence: การประยุกต์ใช้ที่เปลี่ยนเกม

**Seq2Seq** เป็นสถาปัตยกรรมที่ใช้ LSTM สองชุด:

```
Input: "How are you?"
       ↓
   [Encoder LSTM] → [Context Vector] → [Decoder LSTM]
                                           ↓
                                    "สบายดีไหม?"
```

**การประยุกต์ใช้**:
- **Machine Translation**: แปลภาษา (Google Translate รุ่นใหม่)
- **Text Summarization**: สรุปข้อความยาวเป็นสั้น
- **Chatbots**: ตอบกลับในการสนทนา
- **Question Answering**: ตอบคำถามจากข้อมูล

#### ความสำเร็จและข้อจำกัดที่เหลือ

**ความสำเร็จที่โดดเด่น**:
- Google Translate ดีขึ้นอย่างเห็นได้ชัด
- Chatbots เริ่มตอบโต้ได้สมจริง
- Text Summarization เริ่มใช้งานได้จริง

**ข้อจำกัดที่ยังคงอยู่**:

1. **Sequential Processing**: ต้องประมวลผลทีละคำ → ช้า ไม่สามารถ parallelize ได้
2. **Information Bottleneck**: ต้องบีบอัดประโยคทั้งประโยคเป็น vector เดียว
3. **Long-Range Dependencies**: ยังคงมีปัญหากับบริบทที่ยาวมาก
4. **Attention Problem**: ไม่สามารถโฟกัสไปที่ส่วนสำคัญได้โดยตรง

---

## 4. ปี 2017: Transformer - "Attention Is All You Need"

> **"ไม่ต้องประมวลผลทีละคำ ให้มองเห็นทุกคำพร้อมกัน และเลือกโฟกัสที่สำคัญ"**

#### การปฏิวัติครั้งยิ่งใหญ่

ในปี 2017 ทีมวิจัยจาก Google ได้เผยแพร่งานวิจัยที่เปลี่ยนแปลงวงการ AI ไปตลอดกาล ชื่อว่า **"Attention Is All You Need"** ซึ่งแนะนำโมเดล **Transformer** ที่ไม่ต้องพึ่งพา RNN เลย

**คำถามหลัก**: 
> "ถ้าเราสามารถให้โมเดลมองเห็นทุกคำในประโยคพร้อมกัน และเลือกโฟกัสเฉพาะคำที่สำคัญได้โดยตรง จะดีแค่ไหน?"

#### Self-Attention Mechanism: หัวใจของ Transformer

**Self-Attention** ให้แต่ละคำสามารถให้ความสำคัญ (attention) กับคำอื่น ๆ ได้โดยตรง ไม่ว่าจะอยู่ใกล้หรือไกลแค่ไหน

**ตัวอย่างการทำงาน**:
```
ประโยค: "The animal didn't cross the street because it was too tired"

คำว่า "it" จะให้ attention scores:
- "The" = 0.1
- "animal" = 0.8  ← attention สูงสุด
- "didn't" = 0.05
- "cross" = 0.1
- "street" = 0.2
- "because" = 0.05
- "was" = 0.1
- "too" = 0.1
- "tired" = 0.3

→ โมเดลรู้ว่า "it" หมายถึง "animal" ไม่ใช่ "street"
```

**ขั้นตอนการทำงาน**:
1. **Query, Key, Value**: แปลงแต่ละคำเป็น 3 เวกเตอร์
2. **คำนวณ Attention**: หาความเกี่ยวข้องระหว่างคำต่าง ๆ
3. **Weighted Sum**: รวมข้อมูลตามน้ำหนัก attention

#### Multi-Head Attention: มองหลายมุมมองพร้อมกัน

Transformer ไม่ได้ใช้ attention แค่หัวเดียว แต่ใช้ **Multi-Head Attention** ที่เหมือนกับการมองภาพจากหลายมุมมองพร้อมกัน:

```
Head 1: โฟกัสความสัมพันธ์เชิงไวยากรณ์ (ประธาน-กริยา)
Head 2: โฟกัสความสัมพันธ์เชิงความหมาย (คำคุณศัพท์-คำนาม)  
Head 3: โฟกัสความสัมพันธ์ระยะไกล (การอ้างอิง)
Head 4: โฟกัสรูปแบบภาษา (สำนวน, การเน้น)

→ รวมกันเป็นความเข้าใจที่ครอบคลุม
```

#### สถาปัตยกรรม Transformer

**Encoder-Decoder Architecture**:

```
Input Text
    ↓
[Input Embeddings + Positional Encoding]
    ↓
[Multi-Head Self-Attention]
    ↓
[Feed Forward Network]
    ↓ (ทำซ้ำหลายชั้น)
[Encoder Output]
    ↓
[Decoder with Masked Self-Attention]
    ↓
[Encoder-Decoder Attention]
    ↓
[Feed Forward Network]
    ↓
Output Text
```

**องค์ประกอบสำคัญ**:

1. **Positional Encoding**: เนื่องจาก attention ไม่สนใจลำดับ ต้องเพิ่มข้อมูลตำแหน่งให้กับแต่ละคำ

2. **Residual Connections**: เชื่อมต่อข้ามชั้นเพื่อช่วยการเรียนรู้

3. **Layer Normalization**: ปรับปรุงเสถียรภาพการเรียนรู้

#### ข้อดีที่เปลี่ยนเกม

**1. Parallelization**
```
RNN: คำ1 → คำ2 → คำ3 → คำ4 (ต้องทำตามลำดับ)
Transformer: คำ1, คำ2, คำ3, คำ4 (ทำพร้อมกัน)

→ เร็วกว่า RNN มากเมื่อใช้ GPU
```

**2. Long-Range Dependencies**
```
"The cat that we saw yesterday in the park which was full of children is sleeping"

Transformer สามารถเชื่อมโยง "cat" กับ "is sleeping" ได้โดยตรง
โดยไม่ต้องผ่านคำกลาง ๆ ทั้งหมด
```

**3. Interpretability**
```
สามารถดู attention weights เพื่อเข้าใจว่าโมเดล "คิด" อย่างไร
→ ช่วยในการ debug และปรับปรุงโมเดล
```

#### การประยุกต์ใช้และผลกระทบ

**งานที่ Transformer ทำได้ดีเลิศ**:
- **Machine Translation**: แปลภาษาดีกว่า RNN มาก
- **Text Summarization**: สรุปเนื้อหาได้แม่นยำขึ้น  
- **Question Answering**: ตอบคำถามซับซ้อนได้
- **Text Generation**: สร้างข้อความที่สมจริง

**การพัฒนาต่อยอด**:
- **BERT (2018)**: Encoder-only สำหรับความเข้าใจ
- **GPT (2018)**: Decoder-only สำหรับการสร้าง
- **T5 (2019)**: Text-to-Text Transfer Transformer

---

# จาก Transformer สู่ LLM สมัยใหม่

## การพัฒนาต่อเนื่องหลัง 2017

หลังจากการเกิดของ Transformer ในปี 2017 วงการ NLP ได้พัฒนาอย่างรวดเร็ว โดยมีจุดเปลี่ยนสำคัญ:

**2018: BERT และ GPT รุ่นแรก**
- **BERT** (Bidirectional Encoder Representations from Transformers): ใช้ Encoder-only เพื่อความเข้าใจ
- **GPT-1** (Generative Pre-trained Transformer): ใช้ Decoder-only เพื่อการสร้าง

**2019-2020: การขยายขนาด**
- **GPT-2** (1.5B parameters): เริ่มแสดงความสามารถที่น่าทึ่ง
- **GPT-3** (175B parameters): จุดเปลี่ยนสู่ยุค LLM จริง ๆ

**2022-ปัจจุบัน: ยุค ChatGPT และ LLM ใหญ่**
- **ChatGPT/GPT-4**: เพิ่ม instruction tuning และ RLHF
- **Claude, Gemini, LLaMA**: การแข่งขันและพัฒนาต่อเนื่อง

## สามปัจจัยหลักที่ทำให้ LLM สมัยใหม่ "ฉลาด"

LLM ในปัจจุบันยังคงใช้สถาปัตยกรรมพื้นฐานของ Transformer แต่สิ่งที่เปลี่ยนแปลงอย่างมหาศาลคือ:

### 1. ขนาดที่ใหญ่ขึ้นอย่างมหาศาล (Massive Scale-up)

```
Era Timeline:
2017: Transformer Original ~ 65M parameters
2018: GPT-1 ~ 117M parameters  
2019: GPT-2 ~ 1.5B parameters
2020: GPT-3 ~ 175B parameters
2023: GPT-4 ~ 1.76T parameters (ประมาณการ)
```

จำนวนพารามิเตอร์ที่เพิ่มขึ้นอย่างก้าวกระโดดทำให้โมเดลมี "ความจุ" ในการเรียนรู้และจดจำรูปแบบที่ซับซ้อนได้มากขึ้นอย่างไม่เคยมีมาก่อน

### 2. ข้อมูลมหาศาลและหลากหลาย (Vast and Diverse Data)

**ขนาดข้อมูล**:
```
GPT-1 (2018): ~5GB ข้อความ  
GPT-2 (2019): ~40GB ข้อความ
GPT-3 (2020): ~570GB ข้อความ (Common Crawl, WebText, Books, Wikipedia)
GPT-4 (2023): หลายร้อย TB (ข้อความ + โค้ด + อื่นๆ)
```

**ความหลากหลาย**: หนังสือ, บทความ, โค้ด, การสนทนา, เอกสารวิชาการ ทำให้โมเดลมี "ความรู้" ครอบคลุม

### 3. เทคนิคการฝึกที่ปรับปรุง (Advanced Training Techniques)

**Pre-training**: Self-supervised learning ด้วยการทำนายคำถัดไป
**Fine-tuning**: ปรับแต่งสำหรับงานเฉพาะ
**Instruction Tuning**: สอนให้ทำตามคำสั่ง
**RLHF**: Reinforcement Learning from Human Feedback

## ปรากฏการณ์ "Emergent Abilities"

เมื่อรวมสามปัจจัยข้างต้น เกิดปรากฏการณ์ **"ความสามารถที่เกิดขึ้นใหม่"** ที่ไม่เคยมีในโมเดลเล็ก:

### ความสามารถที่โดดเด่น:

**1. In-Context Learning**
```
User: แปลภาษาอังกฤษเป็นไทย
      "Hello" = "สวัสดี"
      "Goodbye" = "ลาก่อน"  
      "Thank you" = ?
      
LLM: "ขอบคุณ"
```

**2. Chain-of-Thought Reasoning**
```
User: หาก 3 คนกิน pizza 1 ชิ้นใน 10 นาที 6 คนจะกินหมดใน ?

LLM: ให้ฉันคิดทีละขั้นตอน:
     1. 3 คน กิน 1 ชิ้นใน 10 นาที
     2. 6 คน = 3 คน × 2
     3. คนเยอะกว่า 2 เท่า → เร็วกว่า 2 เท่า  
     4. 10 นาที ÷ 2 = 5 นาที
```

**3. Multi-Modal Understanding** (GPT-4V, Gemini)
- เข้าใจทั้งข้อความและรูปภาพ
- อธิบายภาพ วิเคราะห์กราฟ อ่านเอกสาร

**4. Code Generation และ Debugging**
- เขียนโค้ดจากคำอธิบาย
- แก้ไขข้อผิดพลาด
- อธิบายโค้ดที่ซับซ้อน

---

# สรุป: จากสถิติสู่ปัญญาเทียม

## การเดินทางที่น่าทึ่ง

จากการนับคำธรรมดา ๆ ในยุค 2013 เราได้เดินทางมาถึงจุดที่ AI สามารถ:
- เข้าใจและสร้างข้อความที่ซับซ้อน
- ให้เหตุผลและแก้ปัญหา  
- เรียนรู้จากตัวอย่างเพียงไม่กี่ตัวอย่าง
- ช่วยเหลือมนุษย์ในงานสร้างสรรค์และงานวิเคราะห์

## 4 จุดเปลี่ยนที่สำคัญ

1. **ยุคสถิติ** → เรียนรู้ความถี่ของคำ
2. **Word2Vec** → เข้าใจความหมายผ่านเวกเตอร์
3. **RNN/LSTM** → เข้าใจลำดับและบริบท
4. **Transformer** → ความสามารถในการ attention และประมวลผลแบบขนาน

## ความหมายสำหรับอนาคต

**แนวทางการเรียนรู้**: การเข้าใจพื้นฐานเหล่านี้จะช่วยให้คุณ:
- ติดตามการพัฒนา AI ได้อย่างมีทิศทาง
- เลือกเครื่องมือและเทคนิคที่เหมาะสม
- เตรียมตัวสำหรับการเปลี่ยนแปลงต่อไป

**ทิศทางอนาคต**: จุดเปลี่ยนครั้งต่อไปอาจจะเป็น:
- **Multimodal AI**: รวม text, image, audio, video
- **Reasoning AI**: ความสามารถในการให้เหตุผลที่ซับซ้อนขึ้น
- **Agent AI**: AI ที่สามารถกระทำการในโลกจริงได้

การเข้าใจรากฐานที่เราได้เรียนรู้ในบทความนี้ จะเป็นเข็มทิศที่ช่วยให้คุณนำทางในโลก AI ที่กำลังเปลี่ยนแปลงอย่างรวดเร็วได้อย่างมั่นใจ

---

*"การเข้าใจอดีตคือกุญแจสำคัญในการทำนายอนาคต และในโลกของ AI การเข้าใจพื้นฐานเหล่านี้คือสิ่งที่จะช่วยให้คุณก้าวทันและใช้ประโยชน์จากเทคโนโลยีที่กำลังเปลี่ยนแปลงโลกอย่างแท้จริง"*